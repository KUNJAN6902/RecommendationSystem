{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A simple heuristic for rating prediction works as follows :\n",
    "    \n",
    "[1] The user(u)'s rating for an item i is a weighted combination of all of their previous ratings for items j\n",
    "\n",
    "[2] The weight for each rating is given by the Jaccard similarity between i and j"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We are going to take a user u's rating for an item i, as a weighted combination of all of the ratings of previous items. \n",
    "\n",
    "So, we have some vector that says, how did the user rate every single other item that have rated j ?\n",
    "\n",
    "But those ratings will be weighted based on how similar those items are to the given query. \n",
    "So items that are more similar to i will be given a higher weight compared to items that are less similar to i. \n",
    "\n",
    "It's really saying, how did you rate things that are similar to the query item and we're going to use that to predict the rating for the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(path, 'rt', encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date']\n"
     ]
    }
   ],
   "source": [
    "header = f.readline()\n",
    "header = header.strip().split('\\t')\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our goal is to make recommendations of products based on users' purchase histories. \n",
    "\n",
    "## The only information needed to do so is user and item IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in f:\n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'marketplace': 'US',\n",
       " 'customer_id': '45610553',\n",
       " 'review_id': 'RMDCHWD0Y5OZ9',\n",
       " 'product_id': 'B00HH62VB6',\n",
       " 'product_parent': '618218723',\n",
       " 'product_title': 'AGPtekÂ® 10 Isolated Output 9V 12V 18V Guitar Pedal Board Power Supply Effect Pedals with Isolated Short Cricuit / Overcurrent Protection',\n",
       " 'product_category': 'Musical Instruments',\n",
       " 'star_rating': 3,\n",
       " 'helpful_votes': 0,\n",
       " 'total_votes': 1,\n",
       " 'vine': 'N',\n",
       " 'verified_purchase': 'N',\n",
       " 'review_headline': 'Three Stars',\n",
       " 'review_body': 'Works very good, but induces ALOT of noise.',\n",
       " 'review_date': '2015-08-31'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To perform set intersections/unions efficiently :\n",
    "\n",
    "## we first build data structures representing the set of items for each user and users for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemNames = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset: \n",
    "    user, item = d['customer_id'], d['product_id']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    itemNames[item] = d['product_title']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=> Types Of Collaborative Filtering :\n",
    "\n",
    "(1) Euclidean Distance based recommendation - It is favored towards small sets, Even if they have few elements in common\n",
    "\n",
    "(2) Jaccard Similarity - Set intersection - ThumbsUp/NoComments\n",
    "\n",
    "(3) Cosine Similarity - Considering angle between vectors rather than set intersections - Works for ThumbsUp/ ThumbsDown/ NoComments\n",
    "\n",
    "(4) Pearson Similarity - Works for Star rating/Numerical rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard(A, B) = |A intersaction B| / |A union B|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We want a recommendation function that return items similar to a candidate item i. Our strategy will be as follows: \n",
    "\n",
    "(1) Find the set of users who purchased i\n",
    "(2) Iterate over all other items other than i\n",
    "(3) For all the other items, compute their similarity with i (and store it)\n",
    "(4) Sort all other items by Jaccard similarity\n",
    "(5) Return the most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(i):\n",
    "    similarities = []\n",
    "    users = usersPerItem[i]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append((sim, i2))\n",
    "    similarities.sort(reverse = True)\n",
    "    return similarities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'marketplace': 'US',\n",
       " 'customer_id': '6111003',\n",
       " 'review_id': 'RIZR67JKUDBI0',\n",
       " 'product_id': 'B0006VMBHI',\n",
       " 'product_parent': '603261968',\n",
       " 'product_title': 'AudioQuest LP record clean brush',\n",
       " 'product_category': 'Musical Instruments',\n",
       " 'star_rating': 3,\n",
       " 'helpful_votes': 0,\n",
       " 'total_votes': 1,\n",
       " 'vine': 'N',\n",
       " 'verified_purchase': 'Y',\n",
       " 'review_headline': 'Three Stars',\n",
       " 'review_body': 'removes dust. does not clean',\n",
       " 'review_date': '2015-08-31'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dataset[2]['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.028446389496717725, 'B00006I5SD'),\n",
       " (0.01694915254237288, 'B00006I5SB'),\n",
       " (0.015065913370998116, 'B000AJR482'),\n",
       " (0.014204545454545454, 'B00E7MVP3S'),\n",
       " (0.008955223880597015, 'B001255YL2'),\n",
       " (0.008849557522123894, 'B003EIRVO8'),\n",
       " (0.008333333333333333, 'B0015VEZ22'),\n",
       " (0.00821917808219178, 'B00006I5UH'),\n",
       " (0.008021390374331552, 'B00008BWM7'),\n",
       " (0.007656967840735069, 'B000H2BC4E')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilar(query)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finally, Let's look at the items that were recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AudioQuest LP record clean brush'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemNames[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shure SFG-2 Stylus Tracking Force Gauge',\n",
       " 'Shure M97xE High-Performance Magnetic Phono Cartridge',\n",
       " 'ART Pro Audio DJPRE II Phono Turntable Preamplifier',\n",
       " 'Signstek Blue LCD Backlight Digital Long-Playing LP Turntable Stylus Force Scale Gauge Tester',\n",
       " 'Audio Technica AT120E/T Standard Mount Phono Cartridge',\n",
       " 'Technics: 45 Adaptor for Technics 1200 (SFWE010)',\n",
       " 'GruvGlide GRUVGLIDE DJ Package',\n",
       " 'STANTON MAGNETICS Record Cleaner Kit',\n",
       " 'Shure M97xE High-Performance Magnetic Phono Cartridge',\n",
       " 'Behringer PP400 Ultra Compact Phono Preamplifier']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[itemNames[x[1]] for x in mostSimilar(query)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "But, This implementation was not very efficient. The slowest component is the iteration over all other items.\n",
    "\n",
    "This can be done more efficiently as most items will have no overlap."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In fact it is sufficient to iterate over those items purchased by one of the users who purchased i.\n",
    "\n",
    "(1) Find the set of users who purchased i\n",
    "(2) Iterate over all users who purchased i\n",
    "(3) Build a candidate set from all items those users consumed\n",
    "(4) For items in this set, compute their similarity with i (and store it)\n",
    "(5) Sort all other items by Jaccard Similarity\n",
    "(6) Return the most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarFast(i):\n",
    "    similarities = []\n",
    "    users = usersPerItem[i]\n",
    "    candidateItems = set()\n",
    "    for u in users:\n",
    "        candidateItems = candidateItems.union(itemsPerUser[u])\n",
    "    for i2 in candidateItems:\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.028446389496717725, 'B00006I5SD'),\n",
       " (0.01694915254237288, 'B00006I5SB'),\n",
       " (0.015065913370998116, 'B000AJR482'),\n",
       " (0.014204545454545454, 'B00E7MVP3S'),\n",
       " (0.008955223880597015, 'B001255YL2'),\n",
       " (0.008849557522123894, 'B003EIRVO8'),\n",
       " (0.008333333333333333, 'B0015VEZ22'),\n",
       " (0.00821917808219178, 'B00006I5UH'),\n",
       " (0.008021390374331552, 'B00008BWM7'),\n",
       " (0.007656967840735069, 'B000H2BC4E')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarFast(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of reviews per user and per item\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    user, item = d['customer_id'], d['product_id']\n",
    "    reviewsPerUser[user].append(d) #Sorting records based on users for reviewsPerUser\n",
    "    reviewsPerItem[item].append(d) #Sorting records based on items for reviewsPerItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingMean = sum([d['star_rating'] for d in dataset]) / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.251102772543146"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(user, item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    \n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['product_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['star_rating'])\n",
    "        similarities.append(Jaccard(usersPerItem[item], usersPerItem[i2]))\n",
    "    \n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings, similarities)]\n",
    "        return sum(weightedRatings)/sum(similarities)\n",
    "    \n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'marketplace': 'US',\n",
       " 'customer_id': '14640079',\n",
       " 'review_id': 'RZSL0BALIYUNU',\n",
       " 'product_id': 'B003LRN53I',\n",
       " 'product_parent': '986692292',\n",
       " 'product_title': 'Sennheiser HD203 Closed-Back DJ Headphones',\n",
       " 'product_category': 'Musical Instruments',\n",
       " 'star_rating': 5,\n",
       " 'helpful_votes': 0,\n",
       " 'total_votes': 0,\n",
       " 'vine': 'N',\n",
       " 'verified_purchase': 'Y',\n",
       " 'review_headline': 'Five Stars',\n",
       " 'review_body': 'Nice headphones at a reasonable price.',\n",
       " 'review_date': '2015-08-31'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, i = dataset[1]['customer_id'], dataset[1]['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictRating(u, i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Conclusion : As shown above, dataset[1] star_rating was 5, and our function predictRating has given us rating as 4.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy across the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences)/len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "alwaysPredictMean = [ratingMean for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [d['star_rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfPredictions = [predictRating(d['customer_id'], d['product_id']) for d in dataset]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MSE(alwaysPredictMean, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6146130004291603"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(cfPredictions, labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Conclusion : alwaysPredictMean is working better than cfPredictions."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note that this is just a Heuristic for rating prediction.\n",
    "\n",
    "In fact, in this case it did worse(in terms of the MSE) than always predicting the mean.\n",
    "\n",
    "We could adapt this to use :\n",
    "    [1] A different similarity function (e.g. cosine)\n",
    "    \n",
    "    [2] Similarity based on users rather than items\n",
    "    \n",
    "    [3] A different weighting scheme rather than a simple weighted average"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=> Compute cosine similarity between samples in X and Y.\n",
    "\n",
    "sklearn.metrics.pairwise.cosine_similarity(X, Y=None, dense_output=True)\n",
    "\n",
    "Cosine similarity, or the cosine kernel, computes similarity as the normalized dot product of X and Y:\n",
    "\n",
    "K(X, Y) = <X, Y> / (||X||*||Y||)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factor Models - Bias only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(dataset)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nItems = len(reviewsPerItem)\n",
    "users = list(reviewsPerUser.keys())\n",
    "items = list(reviewsPerItem.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha and Beta (userbiases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha and beta (userbiases) are parameters we'll fit. \n",
    "#This code sets their initial values (alpha to the mean rating, and beta_u/beta_i to zero)\n",
    "\n",
    "alpha = ratingMean     #initial value to help gradient decent algorithm converge little bit quickly\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our prediction function in this case just implements the bias only model:\n",
    "\n",
    "f(u,i) = alpha + beta_u + beta_i     #beta_u = user_bias, beta_i = item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "The first complex function to implement is this \"unpack\" function. \n",
    "\n",
    "The gradient descent library we'll use expects a single vector of parameters (theta), which we have to unpack to produce alpha and beta:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    \n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1 : nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[nUsers+1 : ]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The next function also required by Gradient Descent library, just implements the full cost function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d['customer_id'], d['product_id']) for d in dataset]\n",
    "    cost = MSE(predictions, labels)\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    \n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next we implement the derivative function, which has a corresponding derivative term for each parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(dataset)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    \n",
    "    for d in dataset:\n",
    "        u, i = d['customer_id'], d['product_id']\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d['star_rating']\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
